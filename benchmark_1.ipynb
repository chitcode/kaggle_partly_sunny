{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Author : Chitrasen\n",
      "#Date : 11/1/2013\n",
      "# Basic benchmark code\n",
      "\n",
      "import pandas as pd\n",
      "from sklearn import cross_validation,metrics\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "def y_binary_p(y,p):\n",
      "    if y <= p:\n",
      "        return 0    \n",
      "    else:\n",
      "        return 1\n",
      "\n",
      "\n",
      "def main():\n",
      "    \n",
      "    print 'reading the datasets ....'\n",
      "    train = pd.read_csv('/home/trupti/data_local/kaggle/partly_sunny/train.csv',header = 0)\n",
      "    test = pd.read_csv('/home/trupti/data_local/kaggle/partly_sunny/test.csv', header = 0)\n",
      "\n",
      "    pred = pd.DataFrame(np.zeros((test.shape[0], train.shape[1]- test.shape[1])), columns = train.columns[4:])\n",
      "    pred.index = test['id']   \n",
      "    \n",
      "    \n",
      "    tweets_train = train['tweet']\n",
      "    tweets_test = test['tweet']\n",
      "\n",
      "\n",
      "    tfidf = TfidfVectorizer(min_df=2,  max_features=None, strip_accents='unicode',  \n",
      "      analyzer='word',token_pattern=r'\\w{1,}',ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1)\n",
      "    \n",
      "    lr = lm.LogisticRegression(penalty='l2', dual=True, tol=0.0001, \n",
      "                           C=1, fit_intercept=True, intercept_scaling=1.0, \n",
      "                           class_weight=None, random_state=None)\n",
      "    \n",
      "    print 'fitting TfIDF...'\n",
      "    trainLen = tweets_train.shape[0]\n",
      "    X_all_a = list(tweets_train)+list(tweets_test)\n",
      "    X_all = [clean(s) for s in X_all_a]\n",
      "\n",
      "    tfidf.fit(X_all)\n",
      "    X_all = tfidf.transform(X_all)\n",
      "    \n",
      "    X_train = X_all[:trainLen]\n",
      "    X_test = X_all[trainLen:]\n",
      "    \n",
      "    vec_y_binary_p = np.vectorize(y_binary_p)\n",
      "    \n",
      "    final_cv_error = 0\n",
      "    \n",
      "    optim_p = {}\n",
      "    \n",
      "    #optim_p = {'s1':0.3,'s2':0.4,'s3':0.4,'s4':0.4,'s5':0.4,'w1':0.6,'w2':0.4,'w3':0.4,'w4':0.3,'k1':0.3,'k2':0.3,'k3':0.3,'k4':0.4,'k5':0.5,'k6':0.1,'k7':0.5,'k8':0.3,'k9':0.3,'k10':0.3,'k11':0.1,'k12':0.4,'k13':0.3,'k14':0.1,'k15':0.5}\n",
      "    print 'Finding the optimum p ... with 10 fold CV'\n",
      "    \n",
      "    kf = cross_validation.KFold(X_train.shape[0],n_folds = 10)\n",
      "    \n",
      "    \n",
      "    for y_col in train.columns[4:]:\n",
      "        min_error = 100\n",
      "        for i in linspace(0.05,1.0,num = 20):\n",
      "            mse_measure = []\n",
      "            for train_idx,cv_idx in kf:\n",
      "                X_train_kf = X_train[train_idx,:]\n",
      "                X_cv_kf = X_train[cv_idx,:]\n",
      "                \n",
      "                y = train[y_col]\n",
      "                y_train_kf = y[train_idx]\n",
      "                y_cv_kf = y[cv_idx]\n",
      "                \n",
      "                y_train_kf = vec_y_binary_p(y_train_kf,i)\n",
      "                lr.fit(X_train_kf,y_train_kf)\n",
      "                               \n",
      "                mse_measure.append(mean_squared_error(y_cv_kf,lr.predict_proba(X_cv_kf)[:,1]))\n",
      "            current_error =  np.mean(mse_measure)\n",
      "            if current_error < min_error:\n",
      "                min_error = current_error\n",
      "                optim_p[y_col] = i\n",
      "            else:\n",
      "                print 'optimum p for ',y_col,optim_p[y_col]\n",
      "                break        \n",
      "    \n",
      "    print 'CV score with optimun p'\n",
      "    \n",
      "    kf = cross_validation.KFold(X_train.shape[0],n_folds = 10)\n",
      "    \n",
      "    final_error = []\n",
      "    j = 0\n",
      "    for train_idx,cv_idx in kf: \n",
      "        j +=1\n",
      "        print 'prcessing CV :',j\n",
      "        X_train_kf = X_train[train_idx,:]\n",
      "        X_cv_kf = X_train[cv_idx,:]\n",
      "        \n",
      "        y_cv_kf = train.ix[cv_idx,4:]\n",
      "        #creating a place holder of cv predictions\n",
      "        pred_cv = pd.DataFrame(np.zeros(y_cv_kf.shape), columns = train.columns[4:])\n",
      "        \n",
      "        error_pred = 100\n",
      "        \n",
      "        for y_col in train.columns[4:]:\n",
      "            y = train[y_col]            \n",
      "            y_train_kf = y[train_idx]            \n",
      "            y_train_kf = vec_y_binary_p(y_train_kf,optim_p[y_col])\n",
      "            \n",
      "            lr.fit(X_train_kf,y_train_kf)\n",
      "            pred_cv[y_col] = lr.predict_proba(X_cv_kf)[:,1]\n",
      "            \n",
      "        error = sqrt(mean_squared_error(y_cv_kf,pred_cv))\n",
      "        final_error.append(error)\n",
      "        print 'final error for cv',j, error\n",
      "    \n",
      "    print 'Mean error for 10 fold CV is ',np.mean(final_error)\n",
      "    \n",
      "    \n",
      "    for y_col in train.columns[4:]:\n",
      "        y = train[y_col]\n",
      "        y = vec_y_binary_p(y,optim_p[y_col])\n",
      "        \n",
      "        lr.fit( X_train, y)\n",
      "        #print lr.predict_proba(X_test)\n",
      "        pred[y_col] = lr.predict_proba(X_test)[:,1]\n",
      "        \n",
      "    pred.to_csv('benchmark_lr_optim_p.csv')\n",
      "    print 'submission file created'\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}